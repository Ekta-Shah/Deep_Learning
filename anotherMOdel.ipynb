{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "anotherMOdel.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXvytOGwRvMP",
        "colab_type": "code",
        "outputId": "547522ea-a901-4cec-977d-bd105e3a869c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a9K3FcyTRtgn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dense\n",
        "from os import listdir\n",
        "import glob\n",
        "import os\n",
        "import cv2\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from __future__ import print_function\n",
        "import os\n",
        "from scipy import misc\n",
        "import glob\n",
        "import matplotlib.pyplot as plt   \n",
        "import sys \n",
        "from scipy.ndimage import rotate\n",
        "#from scipy.misc import imread, imshow\n",
        "import keras\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import numpy as np\n",
        "import sys\n",
        "import shutil\n",
        "import random\n",
        "import numpy as np\n",
        "from keras.models import load_model\n",
        "import pandas as pd\n",
        "import cv2\n",
        "from tensorflow.contrib.keras.api.keras.layers import Dropout\n",
        "from tensorflow.contrib.keras.api.keras.models import Sequential\n",
        "from tensorflow.contrib.keras.api.keras.layers import Conv2D\n",
        "from tensorflow.contrib.keras.api.keras.layers import MaxPooling2D\n",
        "from tensorflow.contrib.keras.api.keras.layers import Flatten\n",
        "from tensorflow.contrib.keras.api.keras.layers import Dense\n",
        "from tensorflow.contrib.keras.api.keras.callbacks import Callback\n",
        "from tensorflow.contrib.keras.api.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.contrib.keras import backend\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQzzttp-Rtgq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "folder_path = '/content/gdrive/My Drive/AI Exam/Image Classification/Data_Cars and Trucks'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpS4SwaGRtgt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trucks_cars=os.listdir(folder_path)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0oCzFlrRtgu",
        "colab_type": "code",
        "outputId": "8601cf5e-80a6-43ae-e613-001d11c1daae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trucks_cars"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['truck', 'car']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfZD7rH6Rtgx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "truck = os.listdir(folder_path+'/'+trucks_cars[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOitH6KiRtgz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cars = os.listdir(folder_path+'/'+trucks_cars[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCzO0mjfRtg1",
        "colab_type": "code",
        "outputId": "87ad06d1-383e-4e26-dfcd-bd403518a9a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(trucks),len(cars)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(392, 402)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnmqrEiaRtg3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trucks_train = trucks[:316]\n",
        "cars_train = cars[:316]\n",
        "trucks_test = trucks[316:]\n",
        "cars_test = cars[316:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oN-JF7YRtg7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.mkdir(folder_path+'/train')\n",
        "os.mkdir(folder_path+'/test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7g8tYmbbRtg8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.mkdir(folder_path+'/train'+'/cars')\n",
        "os.mkdir(folder_path+'/train'+'/trucks')\n",
        "os.mkdir(folder_path+'/test'+'/cars')\n",
        "os.mkdir(folder_path+'/test'+'/trucks')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzDoqaGZRtg_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(0,len(trucks_train)):\n",
        "    image = cv2.imread(folder_path+\"/\"+trucks_cars[1]+'/'+trucks_train[i]) \n",
        "    cv2.imwrite(os.path.join(folder_path+'/train'+'/trucks'+'/'+trucks_train[i]),image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YanX3EkjRthB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for j in range(0,len(cars_train)):\n",
        "    image = cv2.imread(folder_path+\"/\"+trucks_cars[0]+'/'+cars_train[j])\n",
        "    cv2.imwrite(os.path.join(folder_path+'/train'+'/cars'+'/'+cars_train[j]),image)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SN1UiZeRthD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for i in range(0,len(trucks_test)):\n",
        "    image = cv2.imread(folder_path+\"/\"+trucks_cars[1]+'/'+trucks_test[i]) \n",
        "    cv2.imwrite(os.path.join(folder_path+'/test'+'/trucks'+'/'+trucks_test[i]),image)\n",
        "    image1 = cv2.imread(folder_path+\"/\"+trucks_cars[0]+'/'+cars_test[i]) \n",
        "    cv2.imwrite(os.path.join(folder_path+'/test'+'/cars'+'/'+cars_test[i]),image1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6ePnSJlVasM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LossHistory(Callback):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.epoch_id = 0\n",
        "        self.losses = ''\n",
        " \n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        self.losses += \"Epoch {}: accuracy -> {:.4f}, val_accuracy -> {:.4f}\\n\"\\\n",
        "            .format(str(self.epoch_id), logs.get('acc'), logs.get('val_acc'))\n",
        "        self.epoch_id += 1\n",
        " \n",
        "    def on_train_begin(self, logs={}):\n",
        "        self.losses += 'Training begins...\\n'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxRy7bq9VapB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_set_path = os.path.join('/content/gdrive/My Drive/AI Exam/Image Classification/Data_Cars and Trucks/train')\n",
        "test_set_path = os.path.join('/content/gdrive/My Drive/AI Exam/Image Classification/Data_Cars and Trucks/test')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHxFEXYIVamo",
        "colab_type": "code",
        "outputId": "e496ec91-c3a3-4444-d676-d4a6826861d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# Initialising the CNN\n",
        "classifier = Sequential()\n",
        " \n",
        "# Step 1 - Convolution\n",
        "input_size = (192, 192)\n",
        "classifier.add(Conv2D(32, (3, 3), input_shape=(*input_size, 3), activation='relu'))\n",
        " \n",
        "# Step 2 - Pooling\n",
        "classifier.add(MaxPooling2D(pool_size=(2, 2)))  # 2x2 is optimal\n",
        " \n",
        "classifier.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
        " \n",
        "classifier.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
        " \n",
        "classifier.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "classifier.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "# Step 3 - Flattening\n",
        "classifier.add(Flatten())\n",
        " \n",
        "# Step 4 - Full connection\n",
        "classifier.add(Dense(units=64, activation='relu'))\n",
        "classifier.add(Dropout(0.5))\n",
        "classifier.add(Dense(units=2, activation='softmax'))\n",
        " \n",
        "# Compiling the CNN\n",
        "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        " "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qEAVWmRnVajV",
        "colab_type": "code",
        "outputId": "0a702a17-31c0-4b80-ac67-eecc273b0afb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Part 2 - Fitting the CNN to the images\n",
        "batch_size = 32\n",
        "train_datagen = ImageDataGenerator(rescale=1. / 255,\n",
        "                                   shear_range=0.2,\n",
        "                                   zoom_range=0.2,\n",
        "                                   horizontal_flip=True)\n",
        " \n",
        "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
        " \n",
        "training_set = train_datagen.flow_from_directory(training_set_path,\n",
        "                                                 target_size=input_size,\n",
        "                                                 batch_size=batch_size,\n",
        "                                                 class_mode='categorical')\n",
        " \n",
        "test_set = test_datagen.flow_from_directory(test_set_path,\n",
        "                                            target_size=input_size,\n",
        "                                            batch_size=batch_size,\n",
        "                                            class_mode='categorical')\n",
        " "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 632 images belonging to 2 classes.\n",
            "Found 152 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BbjDbHaVahN",
        "colab_type": "code",
        "outputId": "559ea41c-ef3f-4f46-e01d-e2999de081b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Create a loss history\n",
        "history = LossHistory()\n",
        " \n",
        "classifier.fit_generator(training_set,\n",
        "                         steps_per_epoch=632,\n",
        "                         epochs=50,\n",
        "                         validation_data=test_set,\n",
        "                         validation_steps=152,\n",
        "                         workers=12,\n",
        "                         callbacks=[history])\n",
        " "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "630/632 [============================>.] - ETA: 0s - loss: 0.6356 - acc: 0.6144Epoch 1/50\n",
            "632/632 [==============================] - 193s 305ms/step - loss: 0.6351 - acc: 0.6150 - val_loss: 0.8163 - val_acc: 0.6181\n",
            "Epoch 2/50\n",
            "631/632 [============================>.] - ETA: 0s - loss: 0.3565 - acc: 0.8334Epoch 1/50\n",
            "632/632 [==============================] - 190s 301ms/step - loss: 0.3562 - acc: 0.8335 - val_loss: 1.4882 - val_acc: 0.6510\n",
            "Epoch 3/50\n",
            "630/632 [============================>.] - ETA: 0s - loss: 0.1336 - acc: 0.9500Epoch 1/50\n",
            "632/632 [==============================] - 187s 295ms/step - loss: 0.1333 - acc: 0.9501 - val_loss: 1.9456 - val_acc: 0.6726\n",
            "Epoch 4/50\n",
            "631/632 [============================>.] - ETA: 0s - loss: 0.0725 - acc: 0.9755Epoch 1/50\n",
            "632/632 [==============================] - 189s 300ms/step - loss: 0.0724 - acc: 0.9756 - val_loss: 2.5835 - val_acc: 0.6581\n",
            "Epoch 5/50\n",
            "631/632 [============================>.] - ETA: 0s - loss: 0.0425 - acc: 0.9856Epoch 1/50\n",
            "632/632 [==============================] - 188s 298ms/step - loss: 0.0425 - acc: 0.9856 - val_loss: 2.9931 - val_acc: 0.6313\n",
            "Epoch 6/50\n",
            "631/632 [============================>.] - ETA: 0s - loss: 0.0339 - acc: 0.9894Epoch 1/50\n",
            "632/632 [==============================] - 187s 297ms/step - loss: 0.0339 - acc: 0.9894 - val_loss: 2.7097 - val_acc: 0.6254\n",
            "Epoch 7/50\n",
            "631/632 [============================>.] - ETA: 0s - loss: 0.0357 - acc: 0.9883Epoch 1/50\n",
            "632/632 [==============================] - 189s 299ms/step - loss: 0.0360 - acc: 0.9882 - val_loss: 2.6477 - val_acc: 0.6910\n",
            "Epoch 8/50\n",
            "631/632 [============================>.] - ETA: 0s - loss: 0.0281 - acc: 0.9915Epoch 1/50\n",
            "632/632 [==============================] - 186s 295ms/step - loss: 0.0281 - acc: 0.9915 - val_loss: 2.7376 - val_acc: 0.6644\n",
            "Epoch 9/50\n",
            "630/632 [============================>.] - ETA: 0s - loss: 0.0259 - acc: 0.9922Epoch 1/50\n",
            "632/632 [==============================] - 190s 301ms/step - loss: 0.0259 - acc: 0.9922 - val_loss: 2.4985 - val_acc: 0.6914\n",
            "Epoch 10/50\n",
            "630/632 [============================>.] - ETA: 0s - loss: 0.0243 - acc: 0.9923Epoch 1/50\n",
            "632/632 [==============================] - 188s 298ms/step - loss: 0.0243 - acc: 0.9923 - val_loss: 2.4059 - val_acc: 0.5854\n",
            "Epoch 11/50\n",
            "631/632 [============================>.] - ETA: 0s - loss: 0.0220 - acc: 0.9935Epoch 1/50\n",
            "632/632 [==============================] - 187s 296ms/step - loss: 0.0220 - acc: 0.9935 - val_loss: 3.2009 - val_acc: 0.6719\n",
            "Epoch 12/50\n",
            "631/632 [============================>.] - ETA: 0s - loss: 0.0303 - acc: 0.9903Epoch 1/50\n",
            "632/632 [==============================] - 189s 298ms/step - loss: 0.0303 - acc: 0.9903 - val_loss: 2.2536 - val_acc: 0.6972\n",
            "Epoch 13/50\n",
            "629/632 [============================>.] - ETA: 0s - loss: 0.0112 - acc: 0.9968Epoch 1/50\n",
            "632/632 [==============================] - 187s 295ms/step - loss: 0.0111 - acc: 0.9968 - val_loss: 3.0947 - val_acc: 0.6652\n",
            "Epoch 14/50\n",
            "630/632 [============================>.] - ETA: 0s - loss: 0.0289 - acc: 0.9913Epoch 1/50\n",
            "632/632 [==============================] - 191s 303ms/step - loss: 0.0288 - acc: 0.9913 - val_loss: 2.8048 - val_acc: 0.6987\n",
            "Epoch 15/50\n",
            "630/632 [============================>.] - ETA: 0s - loss: 0.0294 - acc: 0.9924Epoch 1/50\n",
            "632/632 [==============================] - 192s 304ms/step - loss: 0.0294 - acc: 0.9924 - val_loss: 2.1376 - val_acc: 0.6840\n",
            "Epoch 16/50\n",
            "630/632 [============================>.] - ETA: 0s - loss: 0.0095 - acc: 0.9970Epoch 1/50\n",
            "632/632 [==============================] - 187s 296ms/step - loss: 0.0095 - acc: 0.9970 - val_loss: 3.2895 - val_acc: 0.6451\n",
            "Epoch 17/50\n",
            "631/632 [============================>.] - ETA: 0s - loss: 0.0260 - acc: 0.9914Epoch 1/50\n",
            "632/632 [==============================] - 188s 298ms/step - loss: 0.0260 - acc: 0.9914 - val_loss: 2.9161 - val_acc: 0.6587\n",
            "Epoch 18/50\n",
            "631/632 [============================>.] - ETA: 0s - loss: 0.0145 - acc: 0.9952Epoch 1/50\n",
            "632/632 [==============================] - 186s 295ms/step - loss: 0.0144 - acc: 0.9952 - val_loss: 3.4286 - val_acc: 0.6445\n",
            "Epoch 19/50\n",
            "630/632 [============================>.] - ETA: 0s - loss: 0.0239 - acc: 0.9934Epoch 1/50\n",
            "632/632 [==============================] - 189s 300ms/step - loss: 0.0238 - acc: 0.9934 - val_loss: 2.5347 - val_acc: 0.6244\n",
            "Epoch 20/50\n",
            "631/632 [============================>.] - ETA: 0s - loss: 0.0104 - acc: 0.9964Epoch 1/50\n",
            "632/632 [==============================] - 189s 299ms/step - loss: 0.0104 - acc: 0.9964 - val_loss: 2.2809 - val_acc: 0.6760\n",
            "Epoch 21/50\n",
            "631/632 [============================>.] - ETA: 0s - loss: 0.0167 - acc: 0.9955Epoch 1/50\n",
            "632/632 [==============================] - 187s 296ms/step - loss: 0.0168 - acc: 0.9955 - val_loss: 3.2032 - val_acc: 0.6447\n",
            "Epoch 22/50\n",
            "629/632 [============================>.] - ETA: 0s - loss: 0.0233 - acc: 0.9932Epoch 1/50\n",
            "632/632 [==============================] - 188s 298ms/step - loss: 0.0232 - acc: 0.9932 - val_loss: 2.7120 - val_acc: 0.7184\n",
            "Epoch 23/50\n",
            "631/632 [============================>.] - ETA: 0s - loss: 0.0067 - acc: 0.9979Epoch 1/50\n",
            "632/632 [==============================] - 186s 295ms/step - loss: 0.0067 - acc: 0.9979 - val_loss: 3.0440 - val_acc: 0.6641\n",
            "Epoch 24/50\n",
            "631/632 [============================>.] - ETA: 0s - loss: 0.0105 - acc: 0.9969Epoch 1/50\n",
            "632/632 [==============================] - 190s 300ms/step - loss: 0.0105 - acc: 0.9969 - val_loss: 3.1210 - val_acc: 0.6717\n",
            "Epoch 25/50\n",
            "630/632 [============================>.] - ETA: 0s - loss: 0.0271 - acc: 0.9923Epoch 1/50\n",
            "632/632 [==============================] - 187s 296ms/step - loss: 0.0270 - acc: 0.9923 - val_loss: 2.8763 - val_acc: 0.6648\n",
            "Epoch 26/50\n",
            "631/632 [============================>.] - ETA: 0s - loss: 0.0107 - acc: 0.9973Epoch 1/50\n",
            "632/632 [==============================] - 187s 296ms/step - loss: 0.0106 - acc: 0.9973 - val_loss: 3.3126 - val_acc: 0.6769\n",
            "Epoch 27/50\n",
            "631/632 [============================>.] - ETA: 0s - loss: 0.0128 - acc: 0.9967Epoch 1/50\n",
            "632/632 [==============================] - 188s 298ms/step - loss: 0.0128 - acc: 0.9967 - val_loss: 3.1855 - val_acc: 0.6505\n",
            "Epoch 28/50\n",
            "631/632 [============================>.] - ETA: 0s - loss: 0.0163 - acc: 0.9950Epoch 1/50\n",
            "632/632 [==============================] - 186s 294ms/step - loss: 0.0162 - acc: 0.9950 - val_loss: 3.0823 - val_acc: 0.6713\n",
            "Epoch 29/50\n",
            "631/632 [============================>.] - ETA: 0s - loss: 0.0137 - acc: 0.9960Epoch 1/50\n",
            "632/632 [==============================] - 190s 300ms/step - loss: 0.0137 - acc: 0.9960 - val_loss: 2.9357 - val_acc: 0.6977\n",
            "Epoch 30/50\n",
            "630/632 [============================>.] - ETA: 0s - loss: 0.0134 - acc: 0.9965Epoch 1/50\n",
            "632/632 [==============================] - 187s 296ms/step - loss: 0.0133 - acc: 0.9965 - val_loss: 3.9020 - val_acc: 0.6051\n",
            "Epoch 31/50\n",
            "631/632 [============================>.] - ETA: 0s - loss: 0.0177 - acc: 0.9947Epoch 1/50\n",
            "632/632 [==============================] - 187s 295ms/step - loss: 0.0178 - acc: 0.9947 - val_loss: 3.4180 - val_acc: 0.6254\n",
            "Epoch 32/50\n",
            "631/632 [============================>.] - ETA: 0s - loss: 0.0029 - acc: 0.9989Epoch 1/50\n",
            "632/632 [==============================] - 188s 298ms/step - loss: 0.0029 - acc: 0.9989 - val_loss: 3.0268 - val_acc: 0.7035\n",
            "Epoch 33/50\n",
            "630/632 [============================>.] - ETA: 0s - loss: 0.0156 - acc: 0.9952Epoch 1/50\n",
            "632/632 [==============================] - 186s 294ms/step - loss: 0.0155 - acc: 0.9952 - val_loss: 3.6952 - val_acc: 0.6574\n",
            "Epoch 34/50\n",
            "630/632 [============================>.] - ETA: 0s - loss: 0.0187 - acc: 0.9955Epoch 1/50\n",
            "632/632 [==============================] - 190s 300ms/step - loss: 0.0186 - acc: 0.9955 - val_loss: 3.5148 - val_acc: 0.6256\n",
            "Epoch 35/50\n",
            "631/632 [============================>.] - ETA: 0s - loss: 0.0086 - acc: 0.9979Epoch 1/50\n",
            "632/632 [==============================] - 187s 297ms/step - loss: 0.0086 - acc: 0.9978 - val_loss: 3.5809 - val_acc: 0.6644\n",
            "Epoch 36/50\n",
            "630/632 [============================>.] - ETA: 0s - loss: 0.0098 - acc: 0.9970Epoch 1/50\n",
            "632/632 [==============================] - 187s 295ms/step - loss: 0.0098 - acc: 0.9970 - val_loss: 3.2255 - val_acc: 0.6698\n",
            "Epoch 37/50\n",
            "631/632 [============================>.] - ETA: 0s - loss: 0.0166 - acc: 0.9954Epoch 1/50\n",
            "632/632 [==============================] - 188s 298ms/step - loss: 0.0165 - acc: 0.9954 - val_loss: 3.2878 - val_acc: 0.6780\n",
            "Epoch 38/50\n",
            "631/632 [============================>.] - ETA: 0s - loss: 0.0091 - acc: 0.9977Epoch 1/50\n",
            "632/632 [==============================] - 186s 295ms/step - loss: 0.0093 - acc: 0.9976 - val_loss: 3.5733 - val_acc: 0.6522\n",
            "Epoch 39/50\n",
            "631/632 [============================>.] - ETA: 0s - loss: 0.0140 - acc: 0.9960Epoch 1/50\n",
            "632/632 [==============================] - 189s 300ms/step - loss: 0.0144 - acc: 0.9960 - val_loss: 2.7944 - val_acc: 0.6585\n",
            "Epoch 40/50\n",
            "629/632 [============================>.] - ETA: 0s - loss: 0.0066 - acc: 0.9980Epoch 1/50\n",
            "632/632 [==============================] - 187s 297ms/step - loss: 0.0065 - acc: 0.9980 - val_loss: 3.6439 - val_acc: 0.6840\n",
            "Epoch 41/50\n",
            "631/632 [============================>.] - ETA: 0s - loss: 0.0074 - acc: 0.9980Epoch 1/50\n",
            "632/632 [==============================] - 186s 295ms/step - loss: 0.0074 - acc: 0.9980 - val_loss: 3.9928 - val_acc: 0.6514\n",
            "Epoch 42/50\n",
            "631/632 [============================>.] - ETA: 0s - loss: 0.0116 - acc: 0.9975Epoch 1/50\n",
            "632/632 [==============================] - 189s 299ms/step - loss: 0.0116 - acc: 0.9975 - val_loss: 3.9248 - val_acc: 0.6380\n",
            "Epoch 43/50\n",
            "631/632 [============================>.] - ETA: 0s - loss: 0.0063 - acc: 0.9981Epoch 1/50\n",
            "632/632 [==============================] - 186s 294ms/step - loss: 0.0063 - acc: 0.9981 - val_loss: 4.1779 - val_acc: 0.6380\n",
            "Epoch 44/50\n",
            "631/632 [============================>.] - ETA: 0s - loss: 0.0136 - acc: 0.9967Epoch 1/50\n",
            "632/632 [==============================] - 190s 301ms/step - loss: 0.0136 - acc: 0.9967 - val_loss: 3.5127 - val_acc: 0.6525\n",
            "Epoch 45/50\n",
            "629/632 [============================>.] - ETA: 0s - loss: 0.0092 - acc: 0.9974Epoch 1/50\n",
            "632/632 [==============================] - 188s 297ms/step - loss: 0.0091 - acc: 0.9974 - val_loss: 3.2672 - val_acc: 0.6566\n",
            "Epoch 46/50\n",
            "630/632 [============================>.] - ETA: 0s - loss: 0.0168 - acc: 0.9957Epoch 1/50\n",
            "632/632 [==============================] - 187s 296ms/step - loss: 0.0168 - acc: 0.9957 - val_loss: 3.1160 - val_acc: 0.6834\n",
            "Epoch 47/50\n",
            "629/632 [============================>.] - ETA: 0s - loss: 0.0097 - acc: 0.9967Epoch 1/50\n",
            "632/632 [==============================] - 189s 298ms/step - loss: 0.0097 - acc: 0.9967 - val_loss: 3.3520 - val_acc: 0.6840\n",
            "Epoch 48/50\n",
            "630/632 [============================>.] - ETA: 0s - loss: 0.0093 - acc: 0.9975Epoch 1/50\n",
            "632/632 [==============================] - 186s 294ms/step - loss: 0.0093 - acc: 0.9974 - val_loss: 3.4881 - val_acc: 0.6650\n",
            "Epoch 49/50\n",
            "631/632 [============================>.] - ETA: 0s - loss: 0.0240 - acc: 0.9947Epoch 1/50\n",
            "632/632 [==============================] - 190s 300ms/step - loss: 0.0240 - acc: 0.9947 - val_loss: 3.2860 - val_acc: 0.6518\n",
            "Epoch 50/50\n",
            "629/632 [============================>.] - ETA: 0s - loss: 0.0055 - acc: 0.9985Epoch 1/50\n",
            "632/632 [==============================] - 188s 297ms/step - loss: 0.0055 - acc: 0.9985 - val_loss: 3.5890 - val_acc: 0.6836\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f33cf71fba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBTLbQcFTKbm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}